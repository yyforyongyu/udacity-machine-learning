{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "traffic light\n",
    "either\n",
    "south-north\n",
    "east-west\n",
    "\n",
    "right of way rules\n",
    "green, turn left, if no coming straight or coming right\n",
    "red, turn right, if no going left\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "always at intersection\n",
    "next state\n",
    "stop, left, right, straight\n",
    "time decreases for each action taken\n",
    "\n",
    "rewards\n",
    "1. complete trip - large\n",
    "2. obey traffic rules - small\n",
    "\n",
    "punishment\n",
    "1. incorrect action - small\n",
    "2. violate traffic rule/cause an accident - large\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION 1\n",
    "Observe what you see with the agent's behavior as it takes random actions. Does the smartcab eventually make it to the destination? Are there any other interesting observations to note?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67.17"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = [60, 68, 67, 61, 71, 71, 71, 74, 71, 67,\n",
    "          69, 68, 68, 70, 63, 70, 58, 66, 65, 69,\n",
    "          62, 75, 72, 67, 67, 67, 67, 73, 64, 58,\n",
    "          72, 71, 62, 71, 67, 63, 65, 69, 61, 71,\n",
    "          69, 69, 70, 63, 69, 65, 66, 68, 72, 60,\n",
    "          65, 66, 67, 64, 64, 70, 62, 65, 68, 67,\n",
    "          66, 64, 68, 69, 67, 69, 60, 66, 73, 64,\n",
    "          62, 75, 66, 65, 65, 68, 68, 71, 72, 70,\n",
    "          67, 72, 73, 62, 68, 67, 75, 72, 74, 66, \n",
    "          68, 62, 67, 64, 60, 69, 70, 59, 65, 69]\n",
    "sum(result) / 100."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The smartcab doesn't not always make to the destination. I ran the simulation 100 times, each time had a total trial of 100. On average, the car could make it at 67.17% of the time. Since all the moves were made randomly, the movement of the car was not making any sense. Sometimes it was hitting other cars, sometimes it just stopped at a green light."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION 2\n",
    "What states have you identified that are appropriate for modeling the smartcab and environment? Why do you believe each of these states to be appropriate for this problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To best make a decision, the following state variables should be considered,\n",
    "\n",
    "+ the next waypoint: this gives us the general direction of where the destination is. We need to approach this direction to finish the trip. The values can be *None, forward, right, left*.\n",
    "\n",
    "+ traffic light: this guides us where to go next to avoid punishment or/and get a reward. The values can be *red or green*.\n",
    "\n",
    "+ presence of another vehicle at the intersection: since we are following Right-of-Way rules, we can then split the situation into four states:\n",
    "    + if I want to go straight, I only care about the traffic light;\n",
    "    + if I want to turn left, when the traffic light is red, is not allowed;\n",
    "    + if I want to turn left, when the traffic light is green, I only care about oncoming cars which are going straight;\n",
    "    + if I want to turn right, when the traffic light is red, I only care about cars on the left;\n",
    "    + if I want to turn right, when the traffic light is green, I have the right of the way, so I don't care about other cars.\n",
    "\n",
    "Given the above thoughts, the values we need to consider are, oncoming traffic - yes or not, and traffic on my left - yes or no.\n",
    "\n",
    "+ deadline: we care about time left. Depending on what rewards we can get from taking each action, if the reward of getting to destination is really high, deadline can be vital since our only goal is to maximize our rewards. An extreme case could be we prefer breaking the traffic law, if our destination reward is so high ( a real life example could be a cop chasing a criminal)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION 2 - OPTIONAL\n",
    "How many states in total exist for the smartcab in this environment? Does this number seem reasonable given that the goal of Q-Learning is to learn and make informed decisions about each state? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 32 states in total. This number seems reasonable to me, as it is fairly small number of states, calculating it would not be difficult."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
